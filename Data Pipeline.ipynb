{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b651a8-908d-4d62-b7ce-86bab6b0eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os \n",
    "import datetime as dt\n",
    "import teradatasql as td\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import datetime\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27102857-aeb2-4e2d-a429-806a1737a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desktop.ini', '~$All Leads - Measurement 10-24-2024 3-05-41 PM.xlsx', '~$High Value New Gamer - New to MGM.pptx', '~$multiprop_spend_data.xlsx']\n",
      "C:\\Users\\Chweber\\Host NBA CRM Stuff\\Host NBA Pipeline\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('C:/Users/Chweber/Downloads'))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c425a-01a2-4112-b76f-c27f09054ba4",
   "metadata": {},
   "source": [
    "<h1> Host NBA CRM Data Pipeline </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9620d7b-9720-455a-8e77-0ea68923c696",
   "metadata": {},
   "source": [
    "<h3>Data Pulling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e284f3ea-34da-4920-a3e7-fba4a7360284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button clicked successfully\n",
      "bedtime\n",
      "bedtime\n",
      "button clicked successfully\n",
      "bedtime\n",
      "button clicked successfully\n",
      "bedtime\n",
      "All files downloaded\n"
     ]
    }
   ],
   "source": [
    "host_dynamics_urls = ['https://mgmhost.crm.dynamics.com/main.aspx?appid=df81b847-7ed4-4d00-bbc4-01b31d607d2a&pagetype=entitylist&etn=task&viewid=5a944623-fe03-ee11-8f6e-6045bd006149&viewType=4230&lid=1722024607660'\n",
    "                      , 'https://mgmhost.crm.dynamics.com/main.aspx?appid=df81b847-7ed4-4d00-bbc4-01b31d607d2a&pagetype=entitylist&etn=task&viewid=356ac88c-fc03-ee11-8f6e-6045bd006793&viewType=4230'\n",
    "                      , 'https://mgmhost.crm.dynamics.com/main.aspx?appid=df81b847-7ed4-4d00-bbc4-01b31d607d2a&pagetype=entitylist&etn=task&viewid=feb7d7bc-fc03-ee11-8f6e-6045bd006793&viewType=4230']\n",
    "\n",
    "with open('asdf.txt','r') as file2:\n",
    "    pw = file2.read()\n",
    "    \n",
    "# download_dir = 'C:/Users/Chweber/Host NBA CRM Stuff/CRM Files'\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(host_dynamics_urls[0])\n",
    "# print(host_dynamics_urls[0])\n",
    "input_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'input.form-control.ltr_override.input.ext-input.text-box.ext-text-box'))\n",
    ")\n",
    "# text_entry = driver.find_element(By.CSS_SELECTOR, 'input.form-control.ltr_override.input.ext-input.text-box.ext-text-box')\n",
    "input_element.send_keys('cweber@mgmresorts.com')\n",
    "input_element.send_keys(Keys.ENTER)\n",
    "\n",
    "input_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'input28'))\n",
    ")\n",
    "input_element.send_keys('604591')\n",
    "input_element.send_keys(Keys.ENTER)\n",
    "\n",
    "input_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, 'input54'))\n",
    ")\n",
    "input_element.send_keys(pw)\n",
    "input_element.send_keys(Keys.ENTER)\n",
    "\n",
    "files = os.listdir('C:/Users/Chweber/Downloads')\n",
    "dwnld_length = len(files)\n",
    "set = dwnld_length\n",
    "\n",
    "n=1\n",
    "try:\n",
    "    while dwnld_length != set+3:\n",
    "        timeout = 1000\n",
    "    \n",
    "        # waits until button loads to click\n",
    "        button = WebDriverWait(driver, timeout).until(\n",
    "            EC.presence_of_element_located((By.ID, 'activitypointer|NoRelationship|HomePageGrid|Mscrm.HomepageGrid.activitypointer.ExportToExcel.Menu$button0'))\n",
    "        )\n",
    "        button.click()\n",
    "        print('button clicked successfully')\n",
    "    \n",
    "        # gets length of the current downloads directory\n",
    "        files = os.listdir('C:/Users/Chweber/Downloads')\n",
    "        set2 = len(files)\n",
    "    \n",
    "        # until the file has finished downloading, keep this loop going\n",
    "        while dwnld_length != set2+1:\n",
    "            print('bedtime')\n",
    "            time.sleep(60)\n",
    "            files = os.listdir('C:/Users/Chweber/Downloads')\n",
    "            dwnld_length = len(files)\n",
    "    \n",
    "        # get next download, caps it at three for each of the host nba markets\n",
    "        # while n < 3:\n",
    "        driver.get(host_dynamics_urls[n])\n",
    "        n+=1\n",
    "        time.sleep(20)\n",
    "except:\n",
    "    print('All files downloaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd74f5bc-d348-42fe-adc8-020daf0daa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Anaconda\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Anaconda\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# gets files from the directory\n",
    "files = os.listdir('C:/Users/Chweber/Downloads')\n",
    "\n",
    "# specifically the three nba files just downloaded\n",
    "files = files[:3]\n",
    "\n",
    "for i in files:\n",
    "    # reads each excel file\n",
    "    excel_file = 'C:/Users/Chweber/Downloads/'+i\n",
    "    # puts file into a dataframe\n",
    "    df = pd.read_excel(excel_file, engine='openpyxl')\n",
    "    # df.to_csv('Host NBA Pipeline/CRM Files/'+i[:-5]+'.csv')\n",
    "    df.to_csv('CRM Files/'+i[:-5]+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114db966-ec9c-4dde-8b8e-981861b50a8f",
   "metadata": {},
   "source": [
    "<h3>Data Cleansing/Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689952a8-4f01-4744-9355-438f18e7ab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#CM. Smart Player Outreach (NBA) - Las Vegas 1-11-2025 12-54-01 PM.csv', '#CM. Smart Player Outreach (NBA) - Las Vegas 1-13-2025 4-38-16 PM.csv', '#CM. Smart Player Outreach (NBA) - PCOMM 1-11-2025 12-55-26 PM.csv', '#CM. Smart Player Outreach (NBA) - PCOMM 1-13-2025 4-39-25 PM.csv', '#CM. Smart Player Outreach (NBA) - Regionals 1-11-2025 12-56-12 PM.csv', '#CM. Smart Player Outreach (NBA) - Regionals 1-13-2025 4-40-25 PM.csv', '.ipynb_checkpoints']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chweber\\AppData\\Local\\Temp\\ipykernel_35696\\1200929538.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Created On'] = pd.to_datetime(df['Created On'].str.replace(r'[^\\d\\-: ]', '', regex=True), errors='raise')\n"
     ]
    }
   ],
   "source": [
    "# file_path = os.listdir('Host NBA Pipeline/CRM Files')\n",
    "file_path = os.listdir('CRM Files')\n",
    "print(file_path)\n",
    "# applies data transformations necessary for SQL queries\n",
    "for i in file_path[:3]:\n",
    "    # df = pd.read_csv('Host NBA Pipeline/CRM Files/'+i)\n",
    "    df = pd.read_csv('CRM Files/'+i)\n",
    "    # removes unwanted columns\n",
    "    df = df.drop(columns=['(Do Not Modify) Task','(Do Not Modify) Row Checksum','(Do Not Modify) Modified On','Unnamed: 0', 'Task Completion Comments'])\n",
    "\n",
    "    # creates Dateloaded column, formats as appropriate for a timestamp value\n",
    "    # df['Dateloaded'] = pd.Timestamp.now().floor('s')\n",
    "    # df['Dateloaded'] = df['Dateloaded'].astype(str)\n",
    "    # df['Dateloaded'] = pd.to_datetime(df['Dateloaded'].str.replace(r'[^\\d\\-: ]', '', regex=True), errors='coerce').dt.normalize()\n",
    "    # df['Dateloaded'] = df['Dateloaded'].dt.strftime('%m-%d-%Y %H:%M:%S')\n",
    "\n",
    "    # converts the columns representing dates to the datetime format\n",
    "    # df['Created On'] = pd.to_datetime(df['Created On'].str.replace(r'[^\\d\\-: ]', '', regex=True),format='%Y-%m-%d', errors='coerce').dt.normalize()\n",
    "    # df['Due Date'] = pd.to_datetime(df['Due Date'].str.replace(r'[^\\d\\-: ]', '', regex=True),format='%Y-%m-%d', errors='coerce').dt.normalize()\n",
    "    # df['Actual End'] = pd.to_datetime(df['Actual End'].str.replace(r'[^\\d\\-: ]', '', regex=True),format='%Y-%m-%d', errors='coerce').dt.normalize()\n",
    "    \n",
    "    df['Created On'] = pd.to_datetime(df['Created On'].str.replace(r'[^\\d\\-: ]', '', regex=True), errors='raise')\n",
    "    df['Due Date'] = pd.to_datetime(df['Due Date'].str.replace(r'[^\\d\\-: ]', '', regex=True), errors='raise')\n",
    "    df['Actual End'] = pd.to_datetime(df['Actual End'].str.replace(r'[^\\d\\-: ]', '', regex=True), errors='raise')\n",
    "    df['Actual End'] = df['Actual End'].fillna(pd.Timestamp.today().normalize()).dt.date\n",
    "\n",
    "\n",
    "    df['Created On'] = pd.to_datetime(df['Created On']).dt.date\n",
    "    df['Due Date'] = pd.to_datetime(df['Due Date']).dt.date\n",
    "    df['Actual End'] = pd.to_datetime(df['Actual End']).dt.date\n",
    "    \n",
    "    # Normalize (strip time information) if datetime parsing is successful\n",
    "    # df['Created On'] = df['Created On'].dt.normalize()\n",
    "    # df['Due Date'] = df['Due Date'].dt.normalize()\n",
    "    # df['Actual End'] = df['Actual End'].dt.normalize()\n",
    "\n",
    "    \n",
    "    # removes all whitespace, necessary for SQL\n",
    "    df = df.rename(columns={'Created On':'Created_On','Host ID (Owning User) (User)':'Host_ID','User Name (Owning User) (User)':'User_Name','Property (Owning User) (User)':'Property','MGM Rewards # (Regarding) (Contact)':'MGM_Rewards_ID','Due Date':'Due_Date','Actual End':'Actual_End','Activity Status':'Activity_Status','Channel Outcome':'Channel_Outcome','NBA ID':'NBA_ID','NBA Type':'NBA_Type'})\n",
    "    \n",
    "    # removes duplicate NBA tasks\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # fills all na with 0\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # ensures data types for each column are appropriate\n",
    "    df['Created_On'] = df['Created_On'].astype(str)\n",
    "    df['Owner'] = df['Owner'].astype(str)\n",
    "    df['Host_ID'] = df['Host_ID'].astype(int)\n",
    "    df['User_Name'] = df['User_Name'].astype(str)\n",
    "    df['Property'] = df['Property'].astype(str)\n",
    "    df['Subject'] = df['Subject'].astype(str)\n",
    "    df['MGM_Rewards_ID'] = df['MGM_Rewards_ID'].astype(int)\n",
    "    df['Regarding'] = df['Regarding'].astype(str)\n",
    "    df['ADW'] = df['ADW'].astype(int)\n",
    "    df['Due_Date'] = df['Due_Date'].astype(str)\n",
    "    df['Actual_End'] = df['Actual_End'].astype(str)\n",
    "    df['Activity_Status'] = df['Activity_Status'].astype(str)\n",
    "    df['Channel'] = df['Channel'].astype(str)\n",
    "    df['Channel_Outcome'] = df['Channel_Outcome'].astype(str)\n",
    "    df['NBA_ID'] = df['NBA_ID'].astype(int)\n",
    "    df['NBA_Type'] = df['NBA_Type'].astype(str)\n",
    "\n",
    "    # uses list comprehension to add Dateloaded as the first column\n",
    "    # columns = ['Dateloaded'] + [col for col in df.columns if col != 'Dateloaded']\n",
    "    columns = [col for col in df.columns if (col != 'Dateloaded' and col != 'ATT (Corp)')]\n",
    "    \n",
    "    # specifies order of columns\n",
    "    df = df[columns]\n",
    "  \n",
    "    # print(df['Created_On'].unique())  \n",
    "    # print(df['Actual_End'].unique())  \n",
    "    # print(df['Due_Date'].unique())  \n",
    "    # creates prepped versions of the dataframes, tab as the delimiter which is necessary for teradata sql import\n",
    "    # df.to_csv('Host NBA Pipeline/Prepped CRM Files/prepped_'+i[:-4]+'.txt', sep = '\\t', index=False)\n",
    "    df.to_csv('Prepped CRM Files/prepped_'+i[:-4]+'.txt', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af66810-3c80-402c-b968-b61b8dd36757",
   "metadata": {},
   "source": [
    "<h3>Teradata Driver Integration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df150504-b910-4b04-a29c-fb26be107a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table...\n",
      "Table creation successful for ae_smart_player_outreach_lv\n",
      "Inserting values...\n",
      "Data import successful\n",
      "Executing query...\n",
      "\tcreate volatile table step1 as\n",
      "\t/*sel * from step1 where prope\n",
      "\t-- select * from step1a where \n",
      "\t/*************  Add in BetMGM \n",
      "\t--select * from step1bb\n",
      " \n",
      "crea\n",
      "\t-- select * from step1c\n",
      "\n",
      "\n",
      "/***\n",
      "\tcreate volatile table step1d a\n",
      "\t--drop table step1g\n",
      "create vol\n",
      "\t--sel * from step1e where trip\n",
      "\t--sel * from step1f where trip\n",
      "\t--select * from step1g\n",
      "/******\n",
      "\t--select * from step2\n",
      "\n",
      "/******\n",
      "\t--select * from step3 sample 1\n",
      "\t--drop table step4\n",
      "create vola\n",
      "\t--sel * from step4\n",
      "-- select *\n",
      "\t/*********************  Add in\n",
      "\t-- select * from step5b order \n",
      "\t-- select * from step5bb order\n",
      "\t-- select * from step5c order \n",
      "\t-- select * from step5d order \n",
      "\t/****************** Create fil\n",
      "\t-- select * from step1g where \n",
      "\t-- select * from step7 order b\n",
      "\t--select * from step8 order by\n",
      "\t/************** Summarized Vie\n",
      "\t/************ Still need to up\n",
      "\tcreate volatile table step10 a\n",
      "\t/************ Summarized Tab O\n",
      "\tcreate table prd_mktg_opr_tb.B\n",
      "Query executed\n",
      "Creating table...\n",
      "Table creation successful for ae_smart_player_outreach_pcomm\n",
      "Inserting values...\n",
      "Data import successful\n",
      "Executing query...\n",
      "\tcreate volatile table step11 a\n",
      "\tcreate volatile table step11ab\n",
      "\t/************** Pull 18 month \n",
      "\tcreate volatile table step11e \n",
      "\tcreate volatile table step11f \n",
      "\tcreate volatile table step11g \n",
      "\t/****************  Pull in PO \n",
      "\t/***********  Pull in Actual T\n",
      "\t--drop table step4\n",
      "create vola\n",
      "\t/************* PO trips ******\n",
      "\t/*********************  Add in\n",
      "\tcreate volatile table step15bb\n",
      "\t--drop table step15c\n",
      "create vo\n",
      "\tcreate volatile table step15d \n",
      "\tcreate volatile table step15e \n",
      "\t/****************** Create fil\n",
      "\tcreate volatile table step17 a\n",
      "\t/************  All trips *****\n",
      "\t/************* Detailed trip l\n",
      "\t--drop table step19a\n",
      "create vo\n",
      "\tcreate volatile table step19b \n",
      "\t/******** Detailed Tab Output \n",
      "\tcreate table prd_mktg_opr_tb.B\n",
      "\t/******** Summary *********/\n",
      "\n",
      "\n",
      "\t/************ Still need to up\n",
      "\t/************ Summarized Tab O\n",
      "\tcreate table prd_mktg_opr_tb.B\n",
      "Query executed\n",
      "Creating table...\n",
      "Table creation successful for ae_smart_player_outreach_reg\n",
      "Inserting values...\n",
      "Data import successful\n",
      "Executing query...\n",
      "\tcreate volatile table step1 as\n"
     ]
    }
   ],
   "source": [
    "# specifies names of the tables \n",
    "table_names = ['ae_smart_player_outreach_lv','ae_smart_player_outreach_pcomm','ae_smart_player_outreach_reg']\n",
    "\n",
    "# grabs location of prepped files\n",
    "prepped_files = os.listdir('Prepped CRM Files')\n",
    "\n",
    "# grabs location of sql queries\n",
    "queries = os.listdir('SQL Queries')\n",
    "\n",
    "# purpose of the function is to create/refresh the tables\n",
    "def table_creation(cur,n):\n",
    "    print('Creating table...')\n",
    "    try:\n",
    "        cur.execute(\"\"\"\n",
    "                    drop table prd_mktg_opr_tb.\"\"\"+table_names[n]\n",
    "                    )\n",
    "    except:\n",
    "        print('table not found')\n",
    "        \n",
    "    cur.execute (\"\"\"\n",
    "                create table prd_mktg_opr_tb.\"\"\"+table_names[n]+\"\"\" (\n",
    "                    Dateloaded TIMESTAMP,\n",
    "                    Created_On varchar(255),\n",
    "                    \"Owner\" varchar(255),\n",
    "                    Host_ID integer,\n",
    "                    User_Name varchar(255),\n",
    "                    Property varchar(255),\n",
    "                    Subject varchar(255),\n",
    "                    MGM_Rewards_ID integer,\n",
    "                    Regarding varchar(255),\n",
    "                    ADW integer,\n",
    "                    Due_Date varchar(255),\n",
    "                    Actual_End varchar(255),\n",
    "                    Activity_Status varchar(255),\n",
    "                    Channel varchar(255),\n",
    "                    Channel_Outcome varchar(255),\n",
    "                    NBA_ID integer,\n",
    "                    NBA_Type varchar(255)\n",
    "                    );\n",
    "                  \"\"\")\n",
    "    print('Table creation successful for '+table_names[n])\n",
    "\n",
    "# purpose of the function is to import the prepped files into the newly created tables\n",
    "def import_to_teradata(df,cur):\n",
    "    try:\n",
    "        # necessary for data import, list out columns and then ? as the wildcard\n",
    "        columns = ', '.join(df.columns)\n",
    "        placeholders = ', '.join(['?' for i in range(len(df.columns))])\n",
    "        # print(columns+'\\n'+placeholders)\n",
    "        \n",
    "        print('Inserting values...')\n",
    "        # sql statement\n",
    "        sql = f\"INSERT INTO prd_mktg_opr_tb.{table_names[n]} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "        # rows\n",
    "        data_to_insert = [tuple(row) for row in df.values]\n",
    "\n",
    "        # directs cursor to import the data \n",
    "        cur.executemany(sql, data_to_insert)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        try:\n",
    "            cur.execute(\"SELECT {fn teradata_get_errors()} AS error_details\")\n",
    "            error_details = cursor.fetchone()\n",
    "            print(\"Error Details:\", error_details)\n",
    "            \n",
    "            cur.execute(\"SELECT {fn teradata_nativesql()} AS native_sql_error\")\n",
    "            native_sql_error = cursor.fetchone()\n",
    "            print(\"Native SQL Error:\", native_sql_error)\n",
    "\n",
    "        except Exception as inner_e:\n",
    "            print(f\"An error occurred while retrieving error details: {inner_e}\")\n",
    "            \n",
    "    finally:\n",
    "        print(\"Data import successful\")\n",
    "    \n",
    "def execute_query(cur,lines): \n",
    "    # breaks apart each query into its individual statements\n",
    "    statements = lines.split(';')\n",
    "\n",
    "    # removes whitespace\n",
    "    statements = [i.strip() for i in statements]\n",
    "    # statements = [i.replace('\\n', '').replace('\\t', '') for i in statements]\n",
    "\n",
    "    # grab the sql statements which involve volatile table creation, select statements, etc.\n",
    "    keywords = [\"create\", \"CREATE\", \"sel\", \"SELECT\",'insert','INSERT','table']\n",
    "    \n",
    "    # only grab the statements which have a match from the list above\n",
    "    statements = [i for i in statements if any(keyword in i for keyword in keywords)]\n",
    "\n",
    "    print('Executing query...')\n",
    "\n",
    "    # iterate over the statements, executing them with the cursor\n",
    "    for i in statements:\n",
    "        print('\\t'+i[:30])\n",
    "        cur.execute(i)\n",
    "    print('Query executed')\n",
    "\n",
    "# grabs password\n",
    "with open('asdf.txt','r') as file2:\n",
    "    pw = file2.read()\n",
    "\n",
    "# for each table which needs refreshing\n",
    "for n in range(3):\n",
    "    # script_dir = os.path.dirname(os.path.abspath(Path.cwd()))\n",
    "    \n",
    "    # getting the absolute path to your prepped file and queries file\n",
    "    prepped_file_path = os.path.join('Prepped CRM Files/',prepped_files[n+1])\n",
    "    queries_file_path = os.path.join('SQL Queries/',queries[n+1])\n",
    "    \n",
    "    # prepped_file_path = 'CRM Files/'+prepped_files[n+1]\n",
    "    # reading each CSV file and queries file using the absolute path\n",
    "    df = pd.read_csv(prepped_file_path,sep='\\t')\n",
    "\n",
    "    # connects to Teradata server, specifies host, logmech, and user to execute queries\n",
    "    with td.connect(host='TDPROD',logmech='LDAP',user='chweber',password=pw) as con:\n",
    "        with con.cursor () as cur: \n",
    "            # create table\n",
    "            table_creation(cur,n)\n",
    "            # import prepped data to these tables\n",
    "            import_to_teradata(df,cur)\n",
    "            # reads query files, passes it to the execute function\n",
    "            with open(queries_file_path,'r') as file:\n",
    "                lines = file.read()\n",
    "            # execute queries, 40+ statements in each\n",
    "            execute_query(cur,lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c1b81-f9b7-4ae6-b49c-a5f3126dbd61",
   "metadata": {},
   "source": [
    "<h4>All that's left is to refresh the Power BI dashboards!</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
